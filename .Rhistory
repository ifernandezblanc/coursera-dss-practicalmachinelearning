trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainURL), na.strings = c("NA", "", "#DIV/0!"))
training$classe <- as.factor(training$classe)
dim(training)
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testURL), na.strings = c("NA", "", "#DIV/0!"))
dim(testing)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain, ]
valSet <- training[-inTrain, ]
allNA <- sapply(trainSet, function(x) mean(is.na(x))) > 0.95 # remove vars with NAs > 95%
trainSet <- trainSet[, allNA == FALSE]
valSet <- valSet[, allNA == FALSE]
nzv <- nearZeroVar(trainSet) # remove variables with near-zero variance
trainSet <- trainSet[, -nzv]
valSet <- valSet[, -nzv]
idVARS <- c(1:7)
trainSet <- trainSet[, -idVARS]
valSet <- valSet[, -idVARS]
dim(trainSet)
dim(valSet)
control <- trainControl(	preProcOptions = list(thresh = 0.8),
allowParallel=T,
savePredictions=T,
method = "cv",
number = 10)
modelFit <- train(classe ~ ., data = trainSet, method = "lda", trControl = control)
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM
rm(list = ls())
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainURL), na.strings = c("NA", "", "#DIV/0!"))
training$classe <- as.factor(training$classe) # Ensure the label variable is treated as a factor
dim(training)
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testURL), na.strings = c("NA", "", "#DIV/0!"))
dim(testing)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain, ]
valSet <- training[-inTrain, ]
allNA <- sapply(trainSet, function(x) mean(is.na(x))) > 0.95 # remove vars with NAs > 95%
trainSet <- trainSet[, allNA == FALSE]
valSet <- valSet[, allNA == FALSE]
nzv <- nearZeroVar(trainSet) # remove variables with near-zero variance
trainSet <- trainSet[, -nzv]
valSet <- valSet[, -nzv]
idVARS <- c(1:7)
trainSet <- trainSet[, -idVARS]
valSet <- valSet[, -idVARS]
dim(trainSet)
dim(valSet)
control <- trainControl(	preProcOptions = list(thresh = 0.8),
allowParallel=T,
savePredictions=T,
method = "cv",
number = 10)
modelFit <- train(classe ~ ., data = trainSet, method = "lda", trControl = control)
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
str(modelCM)
modelCM$overall["Accuracy"]
modelCM
rm(list = ls())
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainURL), na.strings = c("NA", "", "#DIV/0!"))
training$classe <- as.factor(training$classe) # Ensure the label variable is treated as a factor
dim(training)
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testURL), na.strings = c("NA", "", "#DIV/0!"))
dim(testing)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain, ]
valSet <- training[-inTrain, ]
allNA <- sapply(trainSet, function(x) mean(is.na(x))) > 0.95 # remove vars with NAs > 95%
trainSet <- trainSet[, allNA == FALSE]
valSet <- valSet[, allNA == FALSE]
nzv <- nearZeroVar(trainSet) # remove variables with near-zero variance
trainSet <- trainSet[, -nzv]
valSet <- valSet[, -nzv]
idVARS <- c(1:7)
trainSet <- trainSet[, -idVARS]
valSet <- valSet[, -idVARS]
dim(trainSet)
dim(valSet)
# Functions to train each ML algorithm applied sequentially
# Training control parameters
control <- trainControl(	preProcOptions = list(thresh = 0.8),
allowParallel=T,
savePredictions=T,
method = "cv",
number = 10)
# Training function for trainSet
mlTraining <- function (mlMethod) {
modelFit <- train(classe ~ ., data = trainSet, method = mlMethod, trControl = control)
return(modelFit)
}
# Confusion matrix for valSet
mlResult <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
return(data.frame(methodName = modelFit$modelInfo$label, methodResult = modelCM))
}
# List of accuracies obtained for each algorithm applied
mlAccuracy <- function(modelResult) {
return(modelResult$methodName, modelResult$methodResult$overall["Accuracy"])
}
# List of ML algorithms applied
# mlMethods <- c("nb", "lda", "rpart", "gbm", "rf")
mlMethods <- c("lda", "lda")
mlTrains <- lapply(mlMethods, mlTraining)
mlTrains
mlResults <- lapply(mlTrains, mlResult)
mlResult <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM$methodName <- modelFit$modelInfo$label
return(modelCM)
}
mlResults <- lapply(mlTrains, mlResult)
mlResults
mlResults[1]["methodName"]
modelCM <- mlResults[1]
modelCM
modelCM$methodName <- "linear discriminant analysis"
modelCM
str(modelCM)
mlResult <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
return(modelCM)
}
mlResults <- lapply(mlTrains, mlResult)
mlResults
str(mlResults)
mlResult <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM$methodName <- modelFit$modelInfo$label
return(modelCM)
}
mlResults <- lapply(mlTrains, mlResult)
str(mlResults)
mlAccuracy <- function(modelResult) {
return(modelResult$methodName, modelResult$overall["Accuracy"])
}
mlAccuracies <- lapply(mlResults, mlAccuracy)
mlAccuracy <- function(modelResult) {
return(data.frame(modelResult$methodName, modelResult$overall["Accuracy"]))
}
mlAccuracies <- lapply(mlResults, mlAccuracy)
mlAccuracies
as.data.frame(do.call(rbind,(lapply(mlResults, mlAccuracy))))
mlResults
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(caret) # For training models and predicting outcomes
library(randomForest) # For applying random forests' algorithms
set.seed(234332) # For reproducibility purposes
trainURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(url(trainURL), na.strings = c("NA", "", "#DIV/0!"))
training$classe <- as.factor(training$classe) # Ensure the label variable is treated as a factor
dim(training)
testURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testURL), na.strings = c("NA", "", "#DIV/0!"))
dim(testing)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain, ]
valSet <- training[-inTrain, ]
allNA <- sapply(trainSet, function(x) mean(is.na(x))) > 0.95 # remove vars with NAs > 95%
trainSet <- trainSet[, allNA == FALSE]
valSet <- valSet[, allNA == FALSE]
nzv <- nearZeroVar(trainSet) # remove variables with near-zero variance
trainSet <- trainSet[, -nzv]
valSet <- valSet[, -nzv]
idVARS <- c(1:7)
trainSet <- trainSet[, -idVARS]
valSet <- valSet[, -idVARS]
dim(trainSet)
dim(valSet)
# Functions to train each ML algorithm applied sequentially
# Training control parameters
control <- trainControl(	preProcOptions = list(thresh = 0.8),
allowParallel=T,
savePredictions=T,
method = "cv",
number = 10)
# Training function for trainSet
mlTraining <- function (mlMethod) {
modelFit <- train(classe ~ ., data = trainSet, method = mlMethod, trControl = control)
return(modelFit)
}
# Confusion matrix for valSet
mlPredicting <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM$methodName <- modelFit$modelInfo$label
return(modelCM)
}
# Accuracy obtained in valSet for each algorithm applied
mlEvaluating <- function(modelResult) {
return(data.frame(Method = modelResult$methodName, Accuracy = modelResult$overall["Accuracy"]))
}
# List ML algorithms to be applied, train them with trainSet and evaluate their accuracies with valSet
mlMethods <- c("nb", "lda", "rpart", "gbm", "rf")
mlModels <- lapply(mlMethods, mlTraining)
mlResults <- lapply(mlModels, mlPredicting)
# Visualize accuracies in the report, results in the appendices
mlAccuracies <- as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating))))
mlAccuracies
mlModels[1]
plot(mlModels[1])
mlModels[1]$finalModel$tuneValue
str(mlModels[1])
str(mlModels[1]$finalModel)
mlModels
mlModels[3]
str(mlModels[3])
library(rattle)
fancyRpartPlot(mlModels[3])
mlModels[3]$finalModel
mlModels[3]["finalModel"]
mlModels[3][]
plot(mlModels[3][])
str(mlModels[3])
str(mlModels[3][1])
fancyRpartPlot(mlModels[[3]])
fancyRpartPlot(mlModels[[3]]["finalModel"])
mlModels[[3]]$finalModel
plot(mlModels[[3]]$finalModel)
fancyRpartPlot(mlModels[[3]]$finalModel)
getTree(mlModels[[5]]$finalModel)
mlResults
plot(mlResults[[1]]$table, col = mlResults[[1]]$byClass)
mlResults[[1]]$table
mlResults[[1]]$byClass
str(mlResults[[1]]$byClass)
str(data.frame(matrix(unlist(mlResults[[1]]$table), nrow = length(mlResults[[1]]$table), byrow = TRUE)))
data.frame(mlResults[[1]]$table)
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Frequency), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Y)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
str(data.frame(mlResults[[1]]$table))
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") + scale_y_discrete(rev(levels(Prediction)))  +
theme_bw() + theme(legend.position = "none")
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") + scale_y_discrete(rev(levels(data.frame(mlResults[[1]]$table)$Prediction)))  +
theme_bw() + theme(legend.position = "none")
ggplot(data =  data.frame(mlResults[[1]]$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
??fct_rev
library(forcats)
ggplot(data =  data.frame(mlResults[[1]]$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
ggplot(data =  data.frame(mlResults[[1]]$table), mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
mlPlots <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlots)
library(gridExtra)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "blue", high = "red") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
mlPlots <- lapply(mlResults, mlPlotting)
n <- length(mlPlots)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(mlPlots, ncol = nCol))
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "green", high = "blue") +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(breaks=c(0.33,0.66,0.99), labels=c("Low","Medium","High")) +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(breaks=c(0.33,0.90,0.99), labels=c("Low","Medium","High")) +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_manual(
values=c("#08306B", "#4292C6","#C6DBEF"), labels= c("High","Medium","Low","NA")) +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(breaks=c(0.33,0.90,0.99), values=c("#08306B", "#4292C6","#C6DBEF"), labels=c("Low","Medium","High")) +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_tile(aes(fill = Freq), colour = "white") +
geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
scale_fill_gradient(low = "#08306B", high = "#4292C6") +
labs(x = "Reference", y = "Prediction") +
theme_bw() + theme(legend.position = "none")
return(mlPlot)
}
lapply(mlResults, mlPlotting)
plot(mlResults[[1]]$table, col = mlResults[[1]]$byClass)
mlPlotting <- function(mlResult) {
mlPlot <- plot(mlResults[[1]]$table, col = mlResults[[1]]$byClass)
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- plot(mlResult$table, col = mlResult$byClass)
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlots <- lapply(mlResults, mlPlotting)
do.call("grid.arrange", c(mlPlots, ncol = nCol))
mlPlots[1]
install.packages("ggpol")
library(ggpol)
mlPlotting <- function(mlResult) {
mlPlot <- ggplot(data =  data.frame(mlResult$table),
mapping = aes(x = Reference, y = fct_rev(Prediction))) +
geom_confmat()
return(mlPlot)
}
mlPlots <- lapply(mlResults, mlPlotting)
do.call("grid.arrange", c(mlPlots, ncol = nCol))
par(mfrow=c(2,3))
plot(mlResults[[1]]$table, col = mlResults[[1]]$byClass)
plot(mlResults[[2]]$table, col = mlResults[[2]]$byClass)
plot(mlResults[[3]]$table, col = mlResults[[3]]$byClass)
plot(mlResults[[4]]$table, col = mlResults[[4]]$byClass)
plot(mlResults[[5]]$table, col = mlResults[[5]]$byClass)
View(mlResults)
mlPlotting <- function(mlResult) {
mlPlot <- plot(mlResult$table, col = mlResult$byClass,
main = paste(mlResult$methodName, " - Accuracy = ", mlResult$overall["Accuracy"]))
return(mlPlot)
}
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- plot(mlResult$table, col = mlResult$byClass,
main = paste(mlResult$methodName, " - Accuracy = ",
round(mlResult$overall["Accuracy"], 4)))
return(mlPlot)
}
lapply(mlResults, mlPlotting)
layout(matrix(c(1,2,3,4,5,5), nrow = 3, ncol = 2))
layout(matrix(c(1,2,3,4,5,5), nrow = 3, ncol = 2))
lapply(mlResults, mlPlotting)
layout(matrix(c(1,4,2,5,3,6), nrow = 3, ncol = 2))
lapply(mlResults, mlPlotting)
layout(matrix(c(1,2,3,4,5,5), nrow = 3, ncol = 2))
lapply(mlResults, mlPlotting)
layout(matrix(c(1,3,5,2,4,5), nrow = 3, ncol = 2))
lapply(mlResults, mlPlotting)
mlPlotting <- function(mlResult) {
mlPlot <- plot(mlResult$table, col = topo.colors(mlResult$byClass),
main = paste(mlResult$methodName, " - Accuracy = ",
round(mlResult$overall["Accuracy"], 4)))
return(mlPlot)
}
library(cvms)
install.packages("cvms")
library(cvms)
plot_confusion_matrix(mlResults[[1]])
mlResults[[1]]
plot_confusion_matrix(data.frame(mlResults[[1]]$table))
mlModels[[1]]
str(mlModels[[1]])
str(mlModels[[2]])
mlModels[[2]]
mlModels[[1]]
mlModels[[3]]
str(mlModels[[3]])
mlModels[[3]]$finalModel
print(mlModels[[3]])
mlModels[[1]]$results$Accuracy
mlModels[[1]]
mlModels[[2]]$results$Accuracy
mlModels[[3]]$results$Accuracy
mlModels[[4]]$results$Accuracy
mlModels[[5]]$results$Accuracy
max(mlModels[[5]]$results$Accuracy)
max(mlModels[[4]]$results$Accuracy)
max(mlModels[[3]]$results$Accuracy)
max(mlModels[[2]]$results$Accuracy)
max(mlModels[[1]]$results$Accuracy)
mlPredicting <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM$methodName <- modelFit$modelInfo$label
modelCM$methodAccuracy <- max(modelFit$results$Accuracy)
return(modelCM)
}
mlResults <- lapply(mlModels, mlPredicting)
View(mlResults)
mlResults[[2]]
mlResults[[2]]$methodAccuracy
mlEvaluating <- function(modelResult) {
return(data.frame(Method = modelResult$methodName,
In-sample-Error = 1 - modelResult$methodAccuracy,
Out-of-sample-Error = 1 - modelResult$overall["Accuracy"]))
}
mlEvaluating <- function(modelResult) {
return(data.frame(Method = modelResult$methodName,
In_Sample_Error = 1 - modelResult$methodAccuracy,
Out_Of_Sample_Error = 1 - modelResult$overall["Accuracy"]))
}
lapply(mlResults, mlEvaluating)
mlModels[[1]]$modelInfo$label
as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating))))
mlPredicting <- function(modelFit) {
modelPrediction <- predict(modelFit, newdata = valSet)
modelCM <- confusionMatrix(modelPrediction, valSet$classe)
modelCM$methodName <- modelFit$modelInfo$label
print(modelCM$methodName)
modelCM$methodAccuracy <- max(modelFit$results$Accuracy)
return(modelCM)
}
mlResults <- lapply(mlModels, mlPredicting)
warnings()
mlEvaluating <- function(modelResult) {
print(modelResult$methodName)
return(data.frame(Method = modelResult$methodName,
In_Sample_Error = round(1 - modelResult$methodAccuracy, 4),
Out_Of_Sample_Error = round(1 - modelResult$overall["Accuracy"], 4)))
}
as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating))))
mlEvaluating <- function(modelResult) {
print(modelResult$methodName)
return(data.frame(Algorithm = modelResult$methodName,
In_Sample_Error = round(1 - modelResult$methodAccuracy, 4),
Out_Of_Sample_Error = round(1 - modelResult$overall["Accuracy"], 4)))
}
as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating))))
str(as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating)))))
names(as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating)))))
View(as.data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating)))))
data.frame(do.call(rbind,(lapply(mlResults, mlEvaluating))))
